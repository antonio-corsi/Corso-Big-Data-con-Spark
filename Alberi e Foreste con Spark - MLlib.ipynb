{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92869a42",
   "metadata": {},
   "source": [
    "<font size=\"5\">**Breve introduzione agli alberi decisionali ed alle foreste casuali**</font><br>\n",
    "\n",
    "> (c) 2023 Antonio Piemontese "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8149602d",
   "metadata": {},
   "source": [
    "Gli alberi decisionali sono una famiglia di algoritmi in grado di gestire naturalmente predittori sia categorici che numerici. La costruzione di un singolo albero può essere eseguita utilizzando il calcolo parallelo e molti alberi possono essere costruiti in parallelo contemporaneamente. Gli alberi sono robusti rispetto ai valori anomali nei dati, il che significa che alcuni punti dati estremi (*outlier*) e possibilmente errati possono non influenzare affatto le previsioni.<br>\n",
    "\n",
    "Gli alberi possono elaborare dati di tipi diversi e su scale diverse, senza la necessità di pre-elaborazione o normalizzazione (o di standardizzazione). Gli algoritmi basati sull'albero decisionale hanno il vantaggio di essere relativamente intuitivi da comprendere e da ragionarci sopra. In effetti, spesso le persone usano uno schema di ragionamento simile a quello incorporato negli alberi decisionali, nella vita di tutti i giorni. Ad esempio, mi siedo per prendere il caffèlatte mattutino. Prima di scegliere il latte e aggiungerlo al caffè, voglio prevedere: il latte è andato a male? Non lo so per certo. Potrei controllare se la data di scadenza è trascorsa. In caso contrario, prevedo di no, non è andato a male. Se la data è trascorsa, ma erano due o meno giorni fa, corro il rischio e prevedo di no, non è andato a male. Altrimenti annuso il latte. Se ha un odore strano, prevedo di sì, altrimenti di no. Questa serie di decisioni sì/no, che porta appunto ad una previsione, è ciò che incorporano gli alberi decisionali. Ogni decisione porta a uno dei due risultati, ovvero una previsione o un'altra decisione, come mostrato nella seguente figura."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd6164",
   "metadata": {},
   "source": [
    "![](Figure_4_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356d548",
   "metadata": {},
   "source": [
    "E' naturale pensare al processo decisionale come ad **un albero di decisioni**, dove ogni nodo interno all'albero è una decisione, e ogni **nodo foglia** è una risposta finale.<br>\n",
    "\n",
    "Consideriamo un <u>altro esempio</u>. Un robot ha trovato lavoro in un negozio di animali domestici esotici. Vuole sapere, prima che il negozio apra, quali animali nel negozio sarebbero adatti per un bambino, prima che egli venga in negozio. Il proprietario del negozio elenca nove animali domestici che, a suo parere, sono o non sono adatti al bambino, e poi se ne va. Il robot esamina gli animali e ne raccoglie alcune informazioni, elencate nella seguente tabella:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dacf941",
   "metadata": {},
   "source": [
    "![](Table_4_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff387e4",
   "metadata": {},
   "source": [
    "Il robot può scegliere uno dei 9 animali elencati; tuttavia, ci sono molti altri animali domestici disponibili nel negozio. Il robot ha bisogno di un metodo per decidere quali animali tra tutti gli altri possono essere adatti per un bambino.<br>\n",
    "\n",
    "Possiamo presumere che nel negozio siano disponibili animali per tutte le caratteristiche esaminate (*name*,*weight*, *#legs*, *color*) ed anche per le loro combinazioni. Utilizzando i dati decisionali forniti dal proprietario del negozio ed un algoritmo di albero decisionale, possiamo aiutare il robot a capire che aspetto ha un animale domestico per un bambino.<br>\n",
    "\n",
    "Il nome non è una caratteristica utile per questa previsione, e dunque non sarà incluso nel modello di albero decisionale. Infatti, è difficile pensare che il nome da solo sia predittivo; \"Felix\" potrebbe nominare un gatto o una tarantola velenosa, per quanto ne sa il robot. Ci sono due caratteristiche numeriche (peso, numero di zampe) e una caratteristica categorica (colore) che possono aiutare a prevedere la risposta categorica (è/non è un animale domestico adatto per un bambino).<br>\n",
    "\n",
    "Il modo in cui funziona un albero decisionale è: **prendere una o più decisioni in sequenza in base ai predittori forniti**. Per iniziare, il robot può provare ad adattare (*fit*) un semplice albero decisionale a questi dati di training, costituito da una singola decisione, come mostrato qui sotto:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85315c23",
   "metadata": {},
   "source": [
    "![](Figure_4_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6a7738",
   "metadata": {},
   "source": [
    "La logica dell'albero decisionale è di facile comprensione: gli animali di 500 kg sembrano certamente inadatti come animali domestici. Questa regola decisionale, infatti, prevede il valore corretto in <u>cinque dei nove casi</u>. Una rapida occhiata suggerisce che potremmo migliorare la regola abbassando la soglia di peso a 100 kg. Questa regola ottiene <u>sei esempi su nove corretti</u>. Gli animali pesanti ora sono previsti correttamente; gli animali più leggeri sono corretti solo in parte. E' allora possibile costruire **una seconda regola decisionale** per affinare ulteriormente la previsione per animali con peso inferiore a 100 kg. E' utile scegliere un predittore che modifichi alcune delle previsioni Sì errate in No. Ad esempio, c'è un piccolo animale verde, che dal nome potrebbe essere un serpente (!) e che è stato etichettato come non-adatto dal proprietario, che invece è classificato dal nostro primo modello come adatto! Il robot può allora correttamente prevedere come non-adatto semplicemente aggiungendo una decisione basata sul colore, come mostrato nella seguente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2822938",
   "metadata": {},
   "source": [
    "![](Figure_4_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf46fd9",
   "metadata": {},
   "source": [
    "Ora, sette esempi su nove sono classificati correttamente. Naturalmente, altre regole decisionali (ad esempio sul numero di zampe) potrebbero essere aggiunte fino a quando tutte e nove gli esempi non siano previsti correttamente. Tuttavia, la logica incorporata nell'albero decisionale risultante sarebbe probabilmente poco plausibile se tradotta in parole comuni: \"Se il peso dell'animale è inferiore a 100 kg, il suo colore è marrone anziché verde e ha meno di 10 zampe, allora sì, è un animale domestico adatto ad un bambino. Pur adattandosi perfettamente agli esempi forniti, un albero decisionale come questo non riuscirebbe a prevedere che un piccolo lupo marrone a quattro zampe non sia un animale domestico adatto. È necessario un bilanciamento per evitare questo fenomeno, noto come **overfitting**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea31003b",
   "metadata": {},
   "source": [
    "Gli alberi decisionali generalizzano in un algoritmo più potente, chiamato foreste casuali. Le foreste casuali addestrano molti alberi decisionali separatamente e poi li combinano per ridurre il rischio di overfitting. L'algoritmo inserisce casualità nel processo di addestramento in modo che ogni albero decisionale sia leggermente diverso. La combinazione delle previsioni riduce la varianza delle previsioni, rende il modello risultante più generalizzabile e migliora le prestazioni sui dati di test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5027a",
   "metadata": {},
   "source": [
    "# Impostazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29051dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:02:42.854512Z",
     "start_time": "2023-06-28T12:02:35.183300Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "sc = SparkContext('local') # la creazione del contesto Spark \n",
    "spark = SparkSession(sc)   # la creazione della sessione Spark. Servono una decina di secondi di esecuzione.\n",
    "                           # NON si possono creare 2 sessioni contemporaneamente - dà errore!\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c34db",
   "metadata": {},
   "source": [
    "# La preparazione dei dati"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ebc86",
   "metadata": {},
   "source": [
    "Usiamo il famoso dataset **covtype** [che sta per (forest) *cover type*], disponibile [qui](https://archive.ics.uci.edu/dataset/31/covertype).<br>\n",
    "\n",
    "Questo dataset registra i tipi di appezzamenti di terreno in Colorado (USA) coperti da foreste. Ogni riga del dataset contiene diverse caratteristiche che descrivono l'appezzamento di terreno, come: **l'altitudine, la pendenza, la distanza dall'acqua, l'ombra e il tipo di suolo**; inoltre per ogni riga (di training e di test) è noto il **tipo di foresta effettivo** che copre il terreno (<u>la risposta categorica</u>). Il tipo di copertura forestale deve appunto essere previsto in base alle caratteristiche dell'appezzamento, <u>54 in totale</u>. Questo dataset è stato utilizzato nella ricerca e persino in una competizione Kaggle. È un dataset interessante da esplorare anche perché contiene caratteristiche (predittori) sia categoriche che numeriche. Ci sono **581.012 righe**: non è esattamente un esempio di \"big data\", ma è abbastanza per evidenziare alcuni problemi di scala.<br>\n",
    "\n",
    "Per fortuna, i dati sono già in un semplice formato CSV (ancorchè il tipo file sia *.data* e non *.csv*) e non richiedono molta pulizia o altra preparazione per essere utilizzati con **PySpark MLlib**. Il file *covtype.data* deve essere estratto dallo zip e copiato sul PC locale oppure nel cloud (ad esempio, AWS S3).<br>\n",
    "\n",
    "Il file *covtype.info* fornisce molte importanti informazioni, utili da leggere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c22ef1",
   "metadata": {},
   "source": [
    "La creazione di foreste decisionali può richiedere molte risorse computazionali. Se si ha memoria RAM, conviene configurare una sessione Spark con almeno 8GB, cioè: --driver-memory 8g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "013b1917",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:02:48.257245Z",
     "start_time": "2023-06-28T12:02:47.691057Z"
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"8g\").appName('tree_forest').getOrCreate()  # circa 8\" di esecuz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a04eae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:02:54.657525Z",
     "start_time": "2023-06-28T12:02:54.642564Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-5GVTEG7:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x266b58dc5e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "201dbc3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:07:00.624841Z",
     "start_time": "2023-06-28T12:06:55.964011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: integer (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      " |-- _c4: integer (nullable = true)\n",
      " |-- _c5: integer (nullable = true)\n",
      " |-- _c6: integer (nullable = true)\n",
      " |-- _c7: integer (nullable = true)\n",
      " |-- _c8: integer (nullable = true)\n",
      " |-- _c9: integer (nullable = true)\n",
      " |-- _c10: integer (nullable = true)\n",
      " |-- _c11: integer (nullable = true)\n",
      " |-- _c12: integer (nullable = true)\n",
      " |-- _c13: integer (nullable = true)\n",
      " |-- _c14: integer (nullable = true)\n",
      " |-- _c15: integer (nullable = true)\n",
      " |-- _c16: integer (nullable = true)\n",
      " |-- _c17: integer (nullable = true)\n",
      " |-- _c18: integer (nullable = true)\n",
      " |-- _c19: integer (nullable = true)\n",
      " |-- _c20: integer (nullable = true)\n",
      " |-- _c21: integer (nullable = true)\n",
      " |-- _c22: integer (nullable = true)\n",
      " |-- _c23: integer (nullable = true)\n",
      " |-- _c24: integer (nullable = true)\n",
      " |-- _c25: integer (nullable = true)\n",
      " |-- _c26: integer (nullable = true)\n",
      " |-- _c27: integer (nullable = true)\n",
      " |-- _c28: integer (nullable = true)\n",
      " |-- _c29: integer (nullable = true)\n",
      " |-- _c30: integer (nullable = true)\n",
      " |-- _c31: integer (nullable = true)\n",
      " |-- _c32: integer (nullable = true)\n",
      " |-- _c33: integer (nullable = true)\n",
      " |-- _c34: integer (nullable = true)\n",
      " |-- _c35: integer (nullable = true)\n",
      " |-- _c36: integer (nullable = true)\n",
      " |-- _c37: integer (nullable = true)\n",
      " |-- _c38: integer (nullable = true)\n",
      " |-- _c39: integer (nullable = true)\n",
      " |-- _c40: integer (nullable = true)\n",
      " |-- _c41: integer (nullable = true)\n",
      " |-- _c42: integer (nullable = true)\n",
      " |-- _c43: integer (nullable = true)\n",
      " |-- _c44: integer (nullable = true)\n",
      " |-- _c45: integer (nullable = true)\n",
      " |-- _c46: integer (nullable = true)\n",
      " |-- _c47: integer (nullable = true)\n",
      " |-- _c48: integer (nullable = true)\n",
      " |-- _c49: integer (nullable = true)\n",
      " |-- _c50: integer (nullable = true)\n",
      " |-- _c51: integer (nullable = true)\n",
      " |-- _c52: integer (nullable = true)\n",
      " |-- _c53: integer (nullable = true)\n",
      " |-- _c54: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_without_header = spark.read.option(\"inferSchema\", True)\\\n",
    "                      .option(\"header\", False).csv(\"covtype/covtype.data\")   # circa 4\" di esecuzione\n",
    "                      # questo codice non parsifica la prima linea come header; il data-type delle colonne è inferito\n",
    "                      # dall'esame del file; \n",
    "data_without_header.printSchema() # correttamente inferisce che tutte le colonne sono numeriche, e, più esattamente, interi;\n",
    "                                  # non può inferire il nome delle colonne (perchè assente nel file) e dunque assegna\n",
    "                                  # genericamente: _c0, _c1, _c2, ecc.\n",
    "                                  # il significato delle colonne è riportato e ben descritto nel file 'covtype.info'.        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47c0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd                              # comando \"magic\" (cioè che interagisce con il sistema operativo sottostante) per\n",
    "                                  # conoscere la directory corrente (in genere quella dove si trova il notebook che è stato\n",
    "                                  # aperto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ec7d73",
   "metadata": {},
   "source": [
    "![](covtype/covtype_metadata.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551403c",
   "metadata": {},
   "source": [
    "Alcune colonne sono effettivamente numeriche:\n",
    "* l'elevazione è un'elevazione in metri; \n",
    "* la pendenza (*slope*) è misurata in gradi.\n",
    "\n",
    "Tuttavia, *Wilderness_Area* è qualcosa di diverso, perché si dice che si estenda su quattro colonne, ognuna delle quali è uno 0 o 1. In realtà, Wilderness_Area è un valore categorico, non numerico. Queste quattro colonne sono in realtà una [**codifica one-hot**](https://en.wikipedia.org/wiki/One-hot), aka codifica 1-of-N. Quando questa forma di codifica è utilizzata per una caratteristica categoriale, una caratteristica categoriale che assume N valori distinti diventa N caratteristiche numeriche, ciascuna assumendo il valore 0 o 1. Esattamente uno solo degli N valori ha valore 1 e tutti gli altri sono 0. Ad esempio, una caratteristica categorica per il tempo che può essere nuvoloso, piovoso o sereno diventerebbe tre caratteristiche numeriche, dove nuvoloso è rappresentato da 1,0,0; piovoso di 0,1,0; e così via. Queste tre caratteristiche numeriche potrebbero essere considerate come caratteristiche \"è_nuvoloso\", \"è_piovoso\" ed \"è_chiaro\". Quindi, 40 colonne sono in realtà una unica caratteristica categorica *Soil_Type*. La codifica *one_hot* non è l'unico modo possibile per codificare una caratteristica categorica. Un'altra possibile codifica assegna semplicemente un valore numerico distinto a ciascun possibile valore della caratteristica categorica. Ad esempio, nuvoloso può diventare 1.0, piovoso 2.0 e così via. Quindi, nel caso covtype, potremmo avere un'unica variabile numerica *Wilderness_Area* che può assumere uno tra i quattro valori [1,2,3,4]. Il rischio di questa codifica è di sembrare ordinabile, anche se non lo è. Il target *Cover_Type* è un valore categorico codificato come valore da 1 a 7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b571bf3",
   "metadata": {},
   "source": [
    "Prima di procedere, è bene aggiungere al DataFrame i nomi delle colonne per facilitare la comprensione: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccfaa766",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:17:06.431956Z",
     "start_time": "2023-06-28T12:17:06.122783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Wilderness_Area_0=1, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=0, Soil_Type_0=0, Soil_Type_1=0, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=1, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=5.0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "colnames = [\"Elevation\", \"Aspect\", \"Slope\", \\\n",
    "            \"Horizontal_Distance_To_Hydrology\", \\\n",
    "            \"Vertical_Distance_To_Hydrology\", \"Horizontal_Distance_To_Roadways\", \\\n",
    "            \"Hillshade_9am\", \"Hillshade_Noon\", \"Hillshade_3pm\", \\\n",
    "            \"Horizontal_Distance_To_Fire_Points\"] + \\\n",
    "[f\"Wilderness_Area_{i}\" for i in range(4)] + \\\n",
    "[f\"Soil_Type_{i}\" for i in range(40)] + \\\n",
    "[\"Cover_Type\"]\n",
    "\n",
    "data = data_without_header.toDF(*colnames).\\\n",
    "                          withColumn(\"Cover_Type\",\n",
    "                                    col(\"Cover_Type\").cast(DoubleType()))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcf3ad",
   "metadata": {},
   "source": [
    "Note sul codice della cella:\n",
    "* il \"+\" concatena le collezioni\n",
    "* un loop Python genera tutti i nomi delle colonne wilderness\n",
    "* un loop Python genera tutti i nomi delle colonne soil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feee4ae0",
   "metadata": {},
   "source": [
    "Le colonne relative alla natura ed al suolo sono denominate *Wilderness_Area_0*, *Soil_Type_0*, ecc. La colonna  target *Cover_Type* è convertita ad un valore *double* (anzichè *int*), cioè un floating point di due byte, perchè tale è il formato richiesto da tutte le API PySpark di MLlib.<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4589d965",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:21:25.981355Z",
     "start_time": "2023-06-28T12:21:25.970380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Elevation: integer (nullable = true)\n",
      " |-- Aspect: integer (nullable = true)\n",
      " |-- Slope: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Vertical_Distance_To_Hydrology: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Roadways: integer (nullable = true)\n",
      " |-- Hillshade_9am: integer (nullable = true)\n",
      " |-- Hillshade_Noon: integer (nullable = true)\n",
      " |-- Hillshade_3pm: integer (nullable = true)\n",
      " |-- Horizontal_Distance_To_Fire_Points: integer (nullable = true)\n",
      " |-- Wilderness_Area_0: integer (nullable = true)\n",
      " |-- Wilderness_Area_1: integer (nullable = true)\n",
      " |-- Wilderness_Area_2: integer (nullable = true)\n",
      " |-- Wilderness_Area_3: integer (nullable = true)\n",
      " |-- Soil_Type_0: integer (nullable = true)\n",
      " |-- Soil_Type_1: integer (nullable = true)\n",
      " |-- Soil_Type_2: integer (nullable = true)\n",
      " |-- Soil_Type_3: integer (nullable = true)\n",
      " |-- Soil_Type_4: integer (nullable = true)\n",
      " |-- Soil_Type_5: integer (nullable = true)\n",
      " |-- Soil_Type_6: integer (nullable = true)\n",
      " |-- Soil_Type_7: integer (nullable = true)\n",
      " |-- Soil_Type_8: integer (nullable = true)\n",
      " |-- Soil_Type_9: integer (nullable = true)\n",
      " |-- Soil_Type_10: integer (nullable = true)\n",
      " |-- Soil_Type_11: integer (nullable = true)\n",
      " |-- Soil_Type_12: integer (nullable = true)\n",
      " |-- Soil_Type_13: integer (nullable = true)\n",
      " |-- Soil_Type_14: integer (nullable = true)\n",
      " |-- Soil_Type_15: integer (nullable = true)\n",
      " |-- Soil_Type_16: integer (nullable = true)\n",
      " |-- Soil_Type_17: integer (nullable = true)\n",
      " |-- Soil_Type_18: integer (nullable = true)\n",
      " |-- Soil_Type_19: integer (nullable = true)\n",
      " |-- Soil_Type_20: integer (nullable = true)\n",
      " |-- Soil_Type_21: integer (nullable = true)\n",
      " |-- Soil_Type_22: integer (nullable = true)\n",
      " |-- Soil_Type_23: integer (nullable = true)\n",
      " |-- Soil_Type_24: integer (nullable = true)\n",
      " |-- Soil_Type_25: integer (nullable = true)\n",
      " |-- Soil_Type_26: integer (nullable = true)\n",
      " |-- Soil_Type_27: integer (nullable = true)\n",
      " |-- Soil_Type_28: integer (nullable = true)\n",
      " |-- Soil_Type_29: integer (nullable = true)\n",
      " |-- Soil_Type_30: integer (nullable = true)\n",
      " |-- Soil_Type_31: integer (nullable = true)\n",
      " |-- Soil_Type_32: integer (nullable = true)\n",
      " |-- Soil_Type_33: integer (nullable = true)\n",
      " |-- Soil_Type_34: integer (nullable = true)\n",
      " |-- Soil_Type_35: integer (nullable = true)\n",
      " |-- Soil_Type_36: integer (nullable = true)\n",
      " |-- Soil_Type_37: integer (nullable = true)\n",
      " |-- Soil_Type_38: integer (nullable = true)\n",
      " |-- Soil_Type_39: integer (nullable = true)\n",
      " |-- Cover_Type: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c1eaf9",
   "metadata": {},
   "source": [
    "Si può ora eseguire `data.show` per vedere alcune righe del dataset, ma il display è così ampio che è difficile leggerlo tutto. `data.head` lo visualizza come un oggetto *Row* non elaborato, che in questo caso è leggibile. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d71979",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:22:45.626131Z",
     "start_time": "2023-06-28T12:22:45.399225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+-----------------+-----------------+-----------------+-----------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+----------+\n",
      "|Elevation|Aspect|Slope|Horizontal_Distance_To_Hydrology|Vertical_Distance_To_Hydrology|Horizontal_Distance_To_Roadways|Hillshade_9am|Hillshade_Noon|Hillshade_3pm|Horizontal_Distance_To_Fire_Points|Wilderness_Area_0|Wilderness_Area_1|Wilderness_Area_2|Wilderness_Area_3|Soil_Type_0|Soil_Type_1|Soil_Type_2|Soil_Type_3|Soil_Type_4|Soil_Type_5|Soil_Type_6|Soil_Type_7|Soil_Type_8|Soil_Type_9|Soil_Type_10|Soil_Type_11|Soil_Type_12|Soil_Type_13|Soil_Type_14|Soil_Type_15|Soil_Type_16|Soil_Type_17|Soil_Type_18|Soil_Type_19|Soil_Type_20|Soil_Type_21|Soil_Type_22|Soil_Type_23|Soil_Type_24|Soil_Type_25|Soil_Type_26|Soil_Type_27|Soil_Type_28|Soil_Type_29|Soil_Type_30|Soil_Type_31|Soil_Type_32|Soil_Type_33|Soil_Type_34|Soil_Type_35|Soil_Type_36|Soil_Type_37|Soil_Type_38|Soil_Type_39|Cover_Type|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+-----------------+-----------------+-----------------+-----------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+----------+\n",
      "|     2596|    51|    3|                             258|                             0|                            510|          221|           232|          148|                              6279|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2590|    56|    2|                             212|                            -6|                            390|          220|           235|          151|                              6225|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2804|   139|    9|                             268|                            65|                           3180|          234|           238|          135|                              6121|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       2.0|\n",
      "|     2785|   155|   18|                             242|                           118|                           3090|          238|           238|          122|                              6211|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       2.0|\n",
      "|     2595|    45|    2|                             153|                            -1|                            391|          220|           234|          150|                              6172|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2579|   132|    6|                             300|                           -15|                             67|          230|           237|          140|                              6031|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       2.0|\n",
      "|     2606|    45|    7|                             270|                             5|                            633|          222|           225|          138|                              6256|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2605|    49|    4|                             234|                             7|                            573|          222|           230|          144|                              6228|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2617|    45|    9|                             240|                            56|                            666|          223|           221|          133|                              6244|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2612|    59|   10|                             247|                            11|                            636|          228|           219|          124|                              6230|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2612|   201|    4|                             180|                            51|                            735|          218|           243|          161|                              6222|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2886|   151|   11|                             371|                            26|                           5253|          234|           240|          136|                              4051|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       2.0|\n",
      "|     2742|   134|   22|                             150|                            69|                           3215|          248|           224|           92|                              6091|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       2.0|\n",
      "|     2609|   214|    7|                             150|                            46|                            771|          213|           247|          170|                              6211|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2503|   157|    4|                              67|                             4|                            674|          224|           240|          151|                              5600|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2495|    51|    7|                              42|                             2|                            752|          224|           225|          137|                              5576|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2610|   259|    1|                             120|                            -1|                            607|          216|           239|          161|                              6096|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2517|    72|    7|                              85|                             6|                            595|          228|           227|          133|                              5607|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2504|     0|    4|                              95|                             5|                            691|          214|           232|          156|                              5572|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "|     2503|    38|    5|                              85|                            10|                            741|          220|           228|          144|                              5555|                1|                0|                0|                0|          0|          0|          0|          0|          0|          0|          0|          0|          0|          0|           0|           0|           0|           0|           0|           0|           0|           1|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|           0|       5.0|\n",
      "+---------+------+-----+--------------------------------+------------------------------+-------------------------------+-------------+--------------+-------------+----------------------------------+-----------------+-----------------+-----------------+-----------------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+-----------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14cf3722",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:25:01.959080Z",
     "start_time": "2023-06-28T12:25:01.861175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Elevation=2596, Aspect=51, Slope=3, Horizontal_Distance_To_Hydrology=258, Vertical_Distance_To_Hydrology=0, Horizontal_Distance_To_Roadways=510, Hillshade_9am=221, Hillshade_Noon=232, Hillshade_3pm=148, Horizontal_Distance_To_Fire_Points=6279, Wilderness_Area_0=1, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=0, Soil_Type_0=0, Soil_Type_1=0, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=1, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=5.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()   # in parentesi il numero di righe di head (cioè all'inizio del dataframe) che si vogliono leggere.\n",
    "              # il default è 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff005d",
   "metadata": {},
   "source": [
    "Ora che abbiamo un pò di familiarità con il nostro dataset, possiamo **addestrare un modello di albero decisionale**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9fd9ed",
   "metadata": {},
   "source": [
    "# Il primo albero di decisione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71f4317",
   "metadata": {},
   "source": [
    "Suddivisione del dataset in training e test. Come misura di valutazione della qualità predittiva del modello (sui dati di test) useremo l'accuratezza (*accuracy*). Ecco una [rassegna](https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234) delle misure disponibili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85c4971c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:38:45.057311Z",
     "start_time": "2023-06-28T12:38:45.038362Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Elevation: int, Aspect: int, Slope: int, Horizontal_Distance_To_Hydrology: int, Vertical_Distance_To_Hydrology: int, Horizontal_Distance_To_Roadways: int, Hillshade_9am: int, Hillshade_Noon: int, Hillshade_3pm: int, Horizontal_Distance_To_Fire_Points: int, Wilderness_Area_0: int, Wilderness_Area_1: int, Wilderness_Area_2: int, Wilderness_Area_3: int, Soil_Type_0: int, Soil_Type_1: int, Soil_Type_2: int, Soil_Type_3: int, Soil_Type_4: int, Soil_Type_5: int, Soil_Type_6: int, Soil_Type_7: int, Soil_Type_8: int, Soil_Type_9: int, Soil_Type_10: int, Soil_Type_11: int, Soil_Type_12: int, Soil_Type_13: int, Soil_Type_14: int, Soil_Type_15: int, Soil_Type_16: int, Soil_Type_17: int, Soil_Type_18: int, Soil_Type_19: int, Soil_Type_20: int, Soil_Type_21: int, Soil_Type_22: int, Soil_Type_23: int, Soil_Type_24: int, Soil_Type_25: int, Soil_Type_26: int, Soil_Type_27: int, Soil_Type_28: int, Soil_Type_29: int, Soil_Type_30: int, Soil_Type_31: int, Soil_Type_32: int, Soil_Type_33: int, Soil_Type_34: int, Soil_Type_35: int, Soil_Type_36: int, Soil_Type_37: int, Soil_Type_38: int, Soil_Type_39: int, Cover_Type: double]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_data, test_data) = data.randomSplit([0.9, 0.1],seed=1)  \n",
    "                                  # le % 0.9/0.1 sono accettabili considerate le grandi dimensioni\n",
    "                                  # del dataset (circa 60.000 righe di test non sono poche).\n",
    "                                  # il seed (qualsiasi numero!) è essenziale per garantire le RI-PRODUCIBILITA' tra PC.\n",
    "train_data.cache() \n",
    "test_data.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3afd1",
   "metadata": {},
   "source": [
    "Per essere utilizzabile dalle librerie di *MLlib*, il dataframe ha bisogno di un pò di pre-elaborazione: le colonne predittore (ma non la risposta) devono essere raccolte in un [**feature vector**](https://en.wikipedia.org/wiki/Feature_(machine_learning)) (che funziona come un'array di *double*). Ovviamente alcune feature sono concettualmente categoriche, anche se fisicamente sono rappresentate come numeri. [feature vs feature set vs feature vector](https://stats.stackexchange.com/questions/192873/difference-between-feature-feature-set-and-feature-vector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b8d4bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T12:51:48.747581Z",
     "start_time": "2023-06-28T12:51:42.842984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utente\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|featureVector                                                                                       |\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1859.0,18.0,12.0,67.0,11.0,90.0,211.0,215.0,139.0,792.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1860.0,18.0,13.0,95.0,15.0,90.0,210.0,213.0,138.0,780.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1861.0,35.0,14.0,60.0,11.0,85.0,218.0,209.0,124.0,832.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1863.0,37.0,17.0,120.0,18.0,90.0,217.0,202.0,115.0,769.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1866.0,23.0,14.0,85.0,16.0,108.0,212.0,210.0,133.0,819.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1867.0,20.0,15.0,108.0,19.0,120.0,208.0,206.0,132.0,808.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1868.0,27.0,16.0,67.0,17.0,95.0,212.0,204.0,125.0,859.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1871.0,22.0,22.0,60.0,12.0,85.0,200.0,187.0,115.0,792.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1871.0,36.0,19.0,134.0,26.0,120.0,215.0,194.0,107.0,797.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1871.0,37.0,19.0,120.0,29.0,90.0,216.0,195.0,107.0,759.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1872.0,12.0,27.0,85.0,25.0,60.0,182.0,174.0,118.0,577.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1872.0,27.0,16.0,95.0,22.0,124.0,212.0,205.0,126.0,847.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1872.0,27.0,21.0,108.0,30.0,67.0,206.0,190.0,112.0,713.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,14],[1872.0,35.0,21.0,120.0,18.0,85.0,213.0,189.0,104.0,797.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1873.0,30.0,19.0,67.0,21.0,85.0,211.0,195.0,114.0,899.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1876.0,25.0,17.0,124.0,26.0,150.0,209.0,200.0,123.0,836.0,1.0,1.0])|\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1877.0,19.0,18.0,85.0,25.0,108.0,204.0,199.0,127.0,886.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,18],[1877.0,27.0,24.0,90.0,18.0,95.0,201.0,179.0,104.0,780.0,1.0,1.0])  |\n",
      "|(54,[0,1,2,3,4,5,6,7,8,9,13,15],[1877.0,28.0,22.0,127.0,35.0,85.0,205.0,185.0,107.0,706.0,1.0,1.0]) |\n",
      "|(54,[0,1,2,5,6,7,8,9,13,18],[1879.0,18.0,14.0,120.0,208.0,210.0,137.0,767.0,1.0,1.0])               |\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler                   # la funzione di vettorizzazione\n",
    "\n",
    "input_cols = colnames[:-1]                                       # esclude la risposta, il cover_type  (la risposta)\n",
    "\n",
    "# l'inizializzazione:\n",
    "vector_assembler = VectorAssembler(inputCols=input_cols,         # due argomenti in input: le colonne da combinare ed il \n",
    "                                    outputCol=\"featureVector\")   # nome della nuova colonna che contiene il feature vector\n",
    "# la trasformazione:\n",
    "assembled_train_data = vector_assembler.transform(train_data)    # --> il dataframe dei dati di training con le feature \n",
    "                                                                 #     vettorizzate (letter. \"assemblate\")\n",
    "\n",
    "assembled_train_data.select(\"featureVector\").show(truncate = False) # --> un vettore SPARSO (la maggior parte dei 54 \n",
    "                                                                    #     valori è infatti 0) che contiene solo i valori \n",
    "                                                                    #     <> 0 ed i loro indici"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8ea12e",
   "metadata": {},
   "source": [
    "`VectorAssembler` è un esempio di `Transformer`. Trasforma il DataFrame in input in un altro DataFrame. Può essere anche usato dentro le \"pipeline* di trasformazione (vedi più avanti)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb3e833",
   "metadata": {},
   "source": [
    "Costruiamo ora l'albero decisionale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e96f5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T13:01:08.749050Z",
     "start_time": "2023-06-28T13:01:03.095379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_478880a8b56b, depth=5, numNodes=43, numClasses=8, numFeatures=54\n",
      "  If (feature 0 <= 3047.5)\n",
      "   If (feature 0 <= 2561.5)\n",
      "    If (feature 10 <= 0.5)\n",
      "     If (feature 0 <= 2450.5)\n",
      "      If (feature 3 <= 15.0)\n",
      "       Predict: 4.0\n",
      "      Else (feature 3 > 15.0)\n",
      "       Predict: 3.0\n",
      "     Else (feature 0 > 2450.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "    Else (feature 10 > 0.5)\n",
      "     Predict: 2.0\n",
      "   Else (feature 0 > 2561.5)\n",
      "    If (feature 0 <= 2952.5)\n",
      "     If (feature 15 <= 0.5)\n",
      "      If (feature 17 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 17 > 0.5)\n",
      "       Predict: 3.0\n",
      "     Else (feature 15 > 0.5)\n",
      "      Predict: 3.0\n",
      "    Else (feature 0 > 2952.5)\n",
      "     If (feature 3 <= 214.0)\n",
      "      If (feature 36 <= 0.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 36 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 3 > 214.0)\n",
      "      Predict: 2.0\n",
      "  Else (feature 0 > 3047.5)\n",
      "   If (feature 0 <= 3323.5)\n",
      "    If (feature 7 <= 240.5)\n",
      "     Predict: 1.0\n",
      "    Else (feature 7 > 240.5)\n",
      "     If (feature 3 <= 340.5)\n",
      "      Predict: 1.0\n",
      "     Else (feature 3 > 340.5)\n",
      "      If (feature 0 <= 3215.5)\n",
      "       Predict: 2.0\n",
      "      Else (feature 0 > 3215.5)\n",
      "       Predict: 1.0\n",
      "   Else (feature 0 > 3323.5)\n",
      "    If (feature 12 <= 0.5)\n",
      "     If (feature 4 <= 42.5)\n",
      "      If (feature 1 <= 118.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 1 > 118.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 4 > 42.5)\n",
      "      Predict: 1.0\n",
      "    Else (feature 12 > 0.5)\n",
      "     If (feature 45 <= 0.5)\n",
      "      If (feature 44 <= 0.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 44 > 0.5)\n",
      "       Predict: 1.0\n",
      "     Else (feature 45 > 0.5)\n",
      "      If (feature 5 <= 966.5)\n",
      "       Predict: 7.0\n",
      "      Else (feature 5 > 966.5)\n",
      "       Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier              # classe \"classificatori di tipo albero decis.\"\n",
    "\n",
    "# creazione dell'istanza (maiusc+tab dentro la parentesi tonde fornisce la documentazione on-line del classificatore)\n",
    "classifier = DecisionTreeClassifier(seed = 1234, labelCol=\"Cover_Type\",   # la risposta effettiva\n",
    "                                    featuresCol=\"featureVector\",          # il feature vector (i predittori)\n",
    "                                    predictionCol=\"prediction\")           # il nome della colonna che conterrà la previsione\n",
    "\n",
    "# fit del modello\n",
    "model = classifier.fit(assembled_train_data)  # circa 5\" di esecuzione\n",
    "\n",
    "# display dell'albero fittato:\n",
    "print(model.toDebugString)    # --> una struttura ad albero composta da una serie di IF innestate. \n",
    "                              #     Ogni IF confronta i valori della feature con un threshold.\n",
    "                              #     Purtroppo l'albero riporta solo il NUMERO della feature, e non il suo NOME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9c42ab",
   "metadata": {},
   "source": [
    "La classe di creazione dell'istanza ha molti argomenti, alcuni dei quali importanti da capire. [Se si posiziona il cursore dentro le parentesi tonde del creatore dell'istanza e si preme `shift+tab`, compare l'help.]<br>\n",
    "Segue una slide sulla metrica dell'entropia, alternativa a quella di Gini:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552c7230",
   "metadata": {},
   "source": [
    "![](dsfb_0303.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfebb2f",
   "metadata": {},
   "source": [
    "Una caratteristica importante degli alberi decisionali è la loro capacità di [**feature selection**](https://en.wikipedia.org/wiki/Feature_selection). Cioè, possono misurare quanto ogni feature contribuisce o meno all'accuratezza delle previsioni. Queste informazioni sono disponibili nel modello, e si possono facilmente visualizzare in *pandas*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad7c454c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T13:46:11.054939Z",
     "start_time": "2023-06-28T13:46:11.041974Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>0.803527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>0.037767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_0</th>\n",
       "      <td>0.031511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_3</th>\n",
       "      <td>0.030654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>0.025250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_1</th>\n",
       "      <td>0.023805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <td>0.017770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_2</th>\n",
       "      <td>0.011780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_22</th>\n",
       "      <td>0.006761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_30</th>\n",
       "      <td>0.003380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>0.002329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>0.001989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_18</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area_3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_0</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_4</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_5</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type_39</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    importance\n",
       "Elevation                             0.803527\n",
       "Horizontal_Distance_To_Hydrology      0.037767\n",
       "Wilderness_Area_0                     0.031511\n",
       "Soil_Type_3                           0.030654\n",
       "Hillshade_Noon                        0.025250\n",
       "Soil_Type_1                           0.023805\n",
       "Soil_Type_31                          0.017770\n",
       "Wilderness_Area_2                     0.011780\n",
       "Soil_Type_22                          0.006761\n",
       "Vertical_Distance_To_Hydrology        0.003478\n",
       "Soil_Type_30                          0.003380\n",
       "Horizontal_Distance_To_Roadways       0.002329\n",
       "Aspect                                0.001989\n",
       "Soil_Type_27                          0.000000\n",
       "Soil_Type_20                          0.000000\n",
       "Soil_Type_21                          0.000000\n",
       "Soil_Type_23                          0.000000\n",
       "Soil_Type_24                          0.000000\n",
       "Soil_Type_25                          0.000000\n",
       "Soil_Type_26                          0.000000\n",
       "Soil_Type_37                          0.000000\n",
       "Soil_Type_28                          0.000000\n",
       "Soil_Type_29                          0.000000\n",
       "Soil_Type_38                          0.000000\n",
       "Soil_Type_18                          0.000000\n",
       "Soil_Type_32                          0.000000\n",
       "Soil_Type_33                          0.000000\n",
       "Soil_Type_34                          0.000000\n",
       "Soil_Type_35                          0.000000\n",
       "Soil_Type_36                          0.000000\n",
       "Soil_Type_19                          0.000000\n",
       "Soil_Type_13                          0.000000\n",
       "Soil_Type_17                          0.000000\n",
       "Soil_Type_16                          0.000000\n",
       "Slope                                 0.000000\n",
       "Hillshade_9am                         0.000000\n",
       "Hillshade_3pm                         0.000000\n",
       "Horizontal_Distance_To_Fire_Points    0.000000\n",
       "Wilderness_Area_1                     0.000000\n",
       "Wilderness_Area_3                     0.000000\n",
       "Soil_Type_0                           0.000000\n",
       "Soil_Type_2                           0.000000\n",
       "Soil_Type_4                           0.000000\n",
       "Soil_Type_5                           0.000000\n",
       "Soil_Type_6                           0.000000\n",
       "Soil_Type_7                           0.000000\n",
       "Soil_Type_8                           0.000000\n",
       "Soil_Type_9                           0.000000\n",
       "Soil_Type_10                          0.000000\n",
       "Soil_Type_11                          0.000000\n",
       "Soil_Type_12                          0.000000\n",
       "Soil_Type_14                          0.000000\n",
       "Soil_Type_15                          0.000000\n",
       "Soil_Type_39                          0.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# per convertire il DataFrame da Spark a pandas useremo una nuova tecnica (che non avevamo usato nell'esempio dei \n",
    "# record linkage):\n",
    "pd.DataFrame(model.featureImportances.toArray(),\n",
    "            index=input_cols, columns=['importance']).\\\n",
    "            sort_values(by='importance', ascending=False) # --> elenco delle feature dall'importanza più alta in giù;\n",
    "                                                          #     l'importanza della feature è un numero tra 0 ed 1,\n",
    "                                                          #     ed è determinato soprattutto dalla \"altezza\" del nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7f880a",
   "metadata": {},
   "source": [
    "La *elevation* è di gran lunga la feature più importante per prevedere il *cover_type*. La maggior parte delle feature sembra non avere alcuna importanza per la previsione."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d6e52",
   "metadata": {},
   "source": [
    "E' interessante vedere cosa il modello prevede per i dati di training e confrontarlo con il cover_type corretto (noto!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6069330b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T13:59:25.103049Z",
     "start_time": "2023-06-28T13:59:24.976381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|Cover_Type|prediction|probability                                                                                      |\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|3.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |3.0       |[0.0,0.0,0.03419660454341136,0.6303032398603091,0.05127761833961481,0.0,0.2842225372566647,0.0]  |\n",
      "|6.0       |4.0       |[0.0,0.0,0.043610989969472304,0.28085477540340165,0.4348015699956389,0.0,0.24073266463148713,0.0]|\n",
      "+----------+----------+-------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(assembled_train_data)\n",
    "predictions.select(\"Cover_Type\", \"prediction\", \"probability\").\\\n",
    "            show(20, truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bebebce5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:04:36.424281Z",
     "start_time": "2023-06-28T14:04:36.315177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Elevation=1859, Aspect=18, Slope=12, Horizontal_Distance_To_Hydrology=67, Vertical_Distance_To_Hydrology=11, Horizontal_Distance_To_Roadways=90, Hillshade_9am=211, Hillshade_Noon=215, Hillshade_3pm=139, Horizontal_Distance_To_Fire_Points=792, Wilderness_Area_0=0, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=1, Soil_Type_0=0, Soil_Type_1=1, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=0, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=3.0, featureVector=SparseVector(54, {0: 1859.0, 1: 18.0, 2: 12.0, 3: 67.0, 4: 11.0, 5: 90.0, 6: 211.0, 7: 215.0, 8: 139.0, 9: 792.0, 13: 1.0, 15: 1.0}), rawPrediction=DenseVector([0.0, 0.0, 989.0, 18229.0, 1483.0, 0.0, 8220.0, 0.0]), probability=DenseVector([0.0, 0.0, 0.0342, 0.6303, 0.0513, 0.0, 0.2842, 0.0]), prediction=3.0),\n",
       " Row(Elevation=1860, Aspect=18, Slope=13, Horizontal_Distance_To_Hydrology=95, Vertical_Distance_To_Hydrology=15, Horizontal_Distance_To_Roadways=90, Hillshade_9am=210, Hillshade_Noon=213, Hillshade_3pm=138, Horizontal_Distance_To_Fire_Points=780, Wilderness_Area_0=0, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=1, Soil_Type_0=0, Soil_Type_1=1, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=0, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=3.0, featureVector=SparseVector(54, {0: 1860.0, 1: 18.0, 2: 13.0, 3: 95.0, 4: 15.0, 5: 90.0, 6: 210.0, 7: 213.0, 8: 138.0, 9: 780.0, 13: 1.0, 15: 1.0}), rawPrediction=DenseVector([0.0, 0.0, 989.0, 18229.0, 1483.0, 0.0, 8220.0, 0.0]), probability=DenseVector([0.0, 0.0, 0.0342, 0.6303, 0.0513, 0.0, 0.2842, 0.0]), prediction=3.0),\n",
       " Row(Elevation=1861, Aspect=35, Slope=14, Horizontal_Distance_To_Hydrology=60, Vertical_Distance_To_Hydrology=11, Horizontal_Distance_To_Roadways=85, Hillshade_9am=218, Hillshade_Noon=209, Hillshade_3pm=124, Horizontal_Distance_To_Fire_Points=832, Wilderness_Area_0=0, Wilderness_Area_1=0, Wilderness_Area_2=0, Wilderness_Area_3=1, Soil_Type_0=0, Soil_Type_1=1, Soil_Type_2=0, Soil_Type_3=0, Soil_Type_4=0, Soil_Type_5=0, Soil_Type_6=0, Soil_Type_7=0, Soil_Type_8=0, Soil_Type_9=0, Soil_Type_10=0, Soil_Type_11=0, Soil_Type_12=0, Soil_Type_13=0, Soil_Type_14=0, Soil_Type_15=0, Soil_Type_16=0, Soil_Type_17=0, Soil_Type_18=0, Soil_Type_19=0, Soil_Type_20=0, Soil_Type_21=0, Soil_Type_22=0, Soil_Type_23=0, Soil_Type_24=0, Soil_Type_25=0, Soil_Type_26=0, Soil_Type_27=0, Soil_Type_28=0, Soil_Type_29=0, Soil_Type_30=0, Soil_Type_31=0, Soil_Type_32=0, Soil_Type_33=0, Soil_Type_34=0, Soil_Type_35=0, Soil_Type_36=0, Soil_Type_37=0, Soil_Type_38=0, Soil_Type_39=0, Cover_Type=3.0, featureVector=SparseVector(54, {0: 1861.0, 1: 35.0, 2: 14.0, 3: 60.0, 4: 11.0, 5: 85.0, 6: 218.0, 7: 209.0, 8: 124.0, 9: 832.0, 13: 1.0, 15: 1.0}), rawPrediction=DenseVector([0.0, 0.0, 989.0, 18229.0, 1483.0, 0.0, 8220.0, 0.0]), probability=DenseVector([0.0, 0.0, 0.0342, 0.6303, 0.0513, 0.0, 0.2842, 0.0]), prediction=3.0)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.head(3)  # --> 1. l'elenco dei valori dei predittori (feature) per la riga corrente\n",
    "                    #     2. l'elenco delle 7 probbailità di classe per la riga corrente\n",
    "                    #     3. la classe prevista per la riga corrente in base alla probabilità maggiore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60a6ea5",
   "metadata": {},
   "source": [
    "Calcolo dell'**accuratezza predittiva** e della **matrice di confusione** sul <u>training set</u>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4b75ea1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:11:12.364080Z",
     "start_time": "2023-06-28T14:11:10.871288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7015815529469355"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Cover_Type\",\n",
    "                                        predictionCol=\"prediction\")\n",
    "\n",
    "evaluator.setMetricName(\"accuracy\").evaluate(predictions)   # l'accuratezza delle previsioni --> 0.70 (non alta)\n",
    "                                                            # formula: (135917 + 194948 + 25609 + 997 + 0 + 0 + 9433)/522967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f48f3474",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:08:46.568322Z",
     "start_time": "2023-06-28T14:08:44.469417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+------+-----+---+---+---+----+\n",
      "|Cover_Type|     1|     2|    3|  4|  5|  6|   7|\n",
      "+----------+------+------+-----+---+---+---+----+\n",
      "|       1.0|135917| 51129|  166|  0|  0|  0|3584|\n",
      "|       2.0| 55190|194948| 4315|100|  0|  0| 408|\n",
      "|       3.0|     0|  5820|25609|644|  0|  0|   0|\n",
      "|       4.0|     0|    22| 1483|997|  0|  0|   0|\n",
      "|       5.0|    14|  7794|  714|  0|  0|  0|   0|\n",
      "|       6.0|     0|  6156| 8935|552|  0|  0|   0|\n",
      "|       7.0|  8964|    16|   57|  0|  0|  0|9433|\n",
      "+----------+------+------+-----+---+---+---+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = predictions.groupBy(\"Cover_Type\").\\\n",
    "  pivot(\"prediction\", range(1,8)).count().\\\n",
    "  na.fill(0.0).\\\n",
    "  orderBy(\"Cover_Type\")\n",
    "\n",
    "confusion_matrix.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f513b68",
   "metadata": {},
   "source": [
    "Le probabilità delle classi permettono il **ranking** delle previsioni, come si vede in questa slide; ad ogni valore di threshold è associata una **differente matrice di confusione**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8e9d3c",
   "metadata": {},
   "source": [
    "![](dsfb_0801.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d027d88",
   "metadata": {},
   "source": [
    "Scelto un valore di threshold (e quindi la relativa matrice di confusione), se si dispone dei **costi / benefici** <u>indicativi</u> dei vari esiti della classificazione (TP,TN,FP,FN), che sono forniti dal **business** e non dal Data Scientist - dove i benefici sono positivi ed i costi negativi - si può prevedere il valore atteso del beneficio economico dell'utilizzo di un dato classificatore. Ovviamente questo valore atteso dev'essere almeno > 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a78249",
   "metadata": {},
   "source": [
    "![](dsfb_0702.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2532e879",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:16:14.972687Z",
     "start_time": "2023-06-28T14:16:11.080116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(count_proportion=0.36483372755833543),\n",
       " Row(count_proportion=0.4875278937294323),\n",
       " Row(count_proportion=0.061328917503398875),\n",
       " Row(count_proportion=0.004784240688226982),\n",
       " Row(count_proportion=0.016295483271411008),\n",
       " Row(count_proportion=0.02991202121739995),\n",
       " Row(count_proportion=0.0353177160317955)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def class_probabilities(data):\n",
    "    total = data.count()\n",
    "    return data.groupBy(\"Cover_Type\").count().\\\n",
    "    orderBy(\"Cover_Type\").\\\n",
    "    select(col(\"count\").cast(DoubleType())).\\\n",
    "    withColumn(\"count_proportion\", col(\"count\")/total).\\\n",
    "    select(\"count_proportion\").collect()\n",
    "\n",
    "\n",
    "train_prior_probabilities = class_probabilities(train_data)\n",
    "test_prior_probabilities = class_probabilities(test_data)\n",
    "\n",
    "train_prior_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d46b1970",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:16:26.452756Z",
     "start_time": "2023-06-28T14:16:26.438792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3766123651454656"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prior_probabilities = [p[0] for p in train_prior_probabilities]\n",
    "test_prior_probabilities = [p[0] for p in test_prior_probabilities]\n",
    "\n",
    "sum([train_p * cv_p for train_p, cv_p in zip(train_prior_probabilities,\n",
    "                                              test_prior_probabilities)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7830b",
   "metadata": {},
   "source": [
    "# Il tuning dell'albero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f519eb1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:39:44.825221Z",
     "start_time": "2023-06-28T14:39:44.804249Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"featureVector\")\n",
    "classifier = DecisionTreeClassifier(seed=1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"featureVector\",\n",
    "                                    predictionCol=\"prediction\")\n",
    "\n",
    "pipeline = Pipeline(stages=[assembler, classifier])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b8fd6ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:39:46.840382Z",
     "start_time": "2023-06-28T14:39:46.832429Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder  # classe costruttore (builder) della GRIGLIA dei PARAMETRI\n",
    "\n",
    "paramGrid = ParamGridBuilder(). \\\n",
    "  addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "  addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "  addGrid(classifier.maxBins, [40, 300]). \\\n",
    "  addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "  build()\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "  setLabelCol(\"Cover_Type\"). \\\n",
    "  setPredictionCol(\"prediction\"). \\\n",
    "  setMetricName(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "871b4c51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:47:28.915187Z",
     "start_time": "2023-06-28T14:44:57.539392Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234,\n",
    "  estimator=pipeline,\n",
    "  evaluator=multiclassEval,\n",
    "  estimatorParamMaps=paramGrid,\n",
    "  trainRatio=0.9)\n",
    "\n",
    "validator_model = validator.fit(train_data)  # circa 1.5 minuti di esecuzione sul mio PC (4GHz, 16 GB RAM);\n",
    "                                             # sono 16 fit (2^4 = numero di combinazioni dei parametri di input dell'albero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2eacc494",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T14:47:37.225579Z",
     "start_time": "2023-06-28T14:47:37.220590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Param(parent='DecisionTreeClassifier_ef0d3d720050', name='rawPredictionCol', doc='raw prediction (a.k.a. confidence) column name.'): 'rawPrediction',\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minWeightFractionPerNode', doc='Minimum fraction of the weighted sample count that each child must have after split. If a split causes the fraction of the total weight in the left or right child to be less than minWeightFractionPerNode, the split will be discarded as invalid. Should be in interval [0.0, 0.5).'): 0.0,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='predictionCol', doc='prediction column name.'): 'prediction',\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='seed', doc='random seed.'): 1234,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='probabilityCol', doc='Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities.'): 'probability',\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='labelCol', doc='label column name.'): 'Cover_Type',\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='checkpointInterval', doc='set checkpoint interval (>= 1) or disable checkpoint (-1). E.g. 10 means that the cache will get checkpointed every 10 iterations. Note: this setting will be ignored if the checkpoint directory is not set in the SparkContext.'): 10,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='featuresCol', doc='features column name.'): 'featureVector',\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxMemoryInMB', doc='Maximum memory in MB allocated to histogram aggregation. If too small, then 1 node will be split per iteration, and its aggregates may exceed this size.'): 256,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='cacheNodeIds', doc='If false, the algorithm will pass trees to executors to match instances with nodes. If true, the algorithm will cache node IDs for each instance. Caching can speed up training of deeper trees. Users can set how often should the cache be checkpointed or disable it by setting checkpointInterval.'): False,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='leafCol', doc='Leaf indices column name. Predicted leaf index of each instance in each tree by preorder.'): '',\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 1,\n",
      " Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "best_model = validator_model.bestModel           # estrazione best model, cioè dell'albero migliore (rispetto ad una metrica)\n",
    "pprint(best_model.stages[1].extractParamMap())   # display dei parametri ottimali (quelli dell'albero migliore)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034c3e7d",
   "metadata": {},
   "source": [
    "Dall'esame (non banale) delle info della cella precedente, si ricava che la miglior combinazione di parametri dell'albero è data da: maxDepth = 20, impurity = 'entropy', maxBins = 40, minInfoGain = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "03e4cdb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:00:05.245936Z",
     "start_time": "2023-06-28T14:57:34.559630Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.909049299132259,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.9050824830742824,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.9047582721464671,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.9033279298178697,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.7185467721941451,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.7184704872699533,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6694192810145895,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6679507962238963,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 20,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6321922380089635,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.6321922380089635,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.6307618956803661,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.6307618956803661,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.4863736054162296,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.4863736054162296,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 40,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05}),\n",
       " (0.4863736054162296,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.0}),\n",
       " (0.4863736054162296,\n",
       "  {Param(parent='DecisionTreeClassifier_ef0d3d720050', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy',\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 1,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='maxBins', doc='Max number of bins for discretizing continuous features.  Must be >=2 and >= number of categories for any categorical feature.'): 300,\n",
       "   Param(parent='DecisionTreeClassifier_ef0d3d720050', name='minInfoGain', doc='Minimum information gain for a split to be considered at a tree node.'): 0.05})]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator_model = validator.fit(train_data)   # circa 1.5 minuti di esecuzione\n",
    "\n",
    "metrics = validator_model.validationMetrics\n",
    "params = validator_model.getEstimatorParamMaps()\n",
    "metrics_and_params = list(zip(metrics, params))\n",
    "\n",
    "metrics_and_params.sort(key=lambda x: x[0], reverse=True)\n",
    "metrics_and_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "43b2beab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:00:12.855194Z",
     "start_time": "2023-06-28T15:00:12.849203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.909049299132259\n"
     ]
    }
   ],
   "source": [
    "metrics.sort(reverse=True)\n",
    "print(metrics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "de64cf30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:00:20.628842Z",
     "start_time": "2023-06-28T15:00:20.163230Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9049875096907571"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclassEval.evaluate(best_model.transform(test_data)) # l'accuratezza predittiva del miglior albero sui dati di test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6032bf37",
   "metadata": {},
   "source": [
    "# Le variabili categoriche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b57600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "def unencode_one_hot(data):\n",
    "    wilderness_cols = ['Wilderness_Area_' + str(i) for i in range(4)]\n",
    "    wilderness_assembler = VectorAssembler().\\\n",
    "                            setInputCols(wilderness_cols).\\\n",
    "                            setOutputCol(\"wilderness\")\n",
    "\n",
    "    unhot_udf = udf(lambda v: v.toArray().tolist().index(1))\n",
    "\n",
    "    with_wilderness = wilderness_assembler.transform(data).\\\n",
    "      drop(*wilderness_cols).\\\n",
    "      withColumn(\"wilderness\", unhot_udf(col(\"wilderness\")).cast(IntegerType()))\n",
    "\n",
    "    soil_cols = ['Soil_Type_' + str(i) for i in range(40)]\n",
    "    soil_assembler = VectorAssembler().\\\n",
    "                      setInputCols(soil_cols).\\\n",
    "                      setOutputCol(\"soil\")\n",
    "    with_soil = soil_assembler.\\\n",
    "                transform(with_wilderness).\\\n",
    "                drop(*soil_cols).\\\n",
    "                withColumn(\"soil\", unhot_udf(col(\"soil\")).cast(IntegerType()))\n",
    "\n",
    "    return with_soil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e08269",
   "metadata": {},
   "outputs": [],
   "source": [
    "unenc_train_data = unencode_one_hot(train_data)\n",
    "unenc_train_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100ff4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "unenc_train_data.groupBy('wilderness').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f546c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorIndexer\n",
    "\n",
    "cols = unenc_train_data.columns\n",
    "input_cols = [c for c in cols if c!='Cover_Type']\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(input_cols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer().\\\n",
    "  setMaxCategories(40).\\\n",
    "  setInputCol(\"featureVector\").setOutputCol(\"indexedVector\")\n",
    "\n",
    "classifier = DecisionTreeClassifier().setLabelCol(\"Cover_Type\").\\\n",
    "                                      setFeaturesCol(\"indexedVector\").\\\n",
    "                                      setPredictionCol(\"prediction\")\n",
    "\n",
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e50a6",
   "metadata": {},
   "source": [
    "# Foreste di alberi (*random forest*)\n",
    "La costruzione di ogni albero della foresta è indipendente dalle altre ed utilizza un sottoinsieme casuale dei predittori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aae49d41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:26:16.863502Z",
     "start_time": "2023-06-28T15:26:16.815630Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# creazione dell'istanza:\n",
    "classifier = RandomForestClassifier(seed=1234, labelCol=\"Cover_Type\",\n",
    "                                    featuresCol=\"indexedVector\",\n",
    "                                    predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3c90dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:27:55.762187Z",
     "start_time": "2023-06-28T15:27:55.746228Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unenc_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2204/383779250.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munenc_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'unenc_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "unenc_train_data.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00a0d9c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:28:19.037692Z",
     "start_time": "2023-06-28T15:28:19.022731Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unenc_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2204/1310417610.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Skipped in book\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munenc_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0minput_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'Cover_Type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unenc_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Skipped in book\n",
    "\n",
    "cols = unenc_train_data.columns\n",
    "input_cols = [c for c in cols if c!='Cover_Type']\n",
    "\n",
    "assembler = VectorAssembler().setInputCols(input_cols).setOutputCol(\"featureVector\")\n",
    "\n",
    "indexer = VectorIndexer().\\\n",
    "  setMaxCategories(40).\\\n",
    "  setInputCol(\"featureVector\").setOutputCol(\"indexedVector\")\n",
    "\n",
    "pipeline = Pipeline().setStages([assembler, indexer, classifier])\n",
    "\n",
    "paramGrid = ParamGridBuilder(). \\\n",
    "  addGrid(classifier.impurity, [\"gini\", \"entropy\"]). \\\n",
    "  addGrid(classifier.maxDepth, [1, 20]). \\\n",
    "  addGrid(classifier.maxBins, [40, 300]). \\\n",
    "  addGrid(classifier.minInfoGain, [0.0, 0.05]). \\\n",
    "  build()\n",
    "\n",
    "multiclassEval = MulticlassClassificationEvaluator(). \\\n",
    "  setLabelCol(\"Cover_Type\"). \\\n",
    "  setPredictionCol(\"prediction\"). \\\n",
    "  setMetricName(\"accuracy\")\n",
    "\n",
    "validator = TrainValidationSplit(seed=1234,\n",
    "  estimator=pipeline,\n",
    "  evaluator=multiclassEval,\n",
    "  estimatorParamMaps=paramGrid,\n",
    "  trainRatio=0.9)\n",
    "\n",
    "validator_model = validator.fit(unenc_train_data)\n",
    "\n",
    "best_model = validator_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3c1c7ee9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:28:33.217744Z",
     "start_time": "2023-06-28T15:28:33.207771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Elevation', 0.4461487371081402),\n",
      " ('Horizontal_Distance_To_Fire_Points', 0.11037833749499719),\n",
      " ('Horizontal_Distance_To_Roadways', 0.10441123449330059),\n",
      " ('Horizontal_Distance_To_Hydrology', 0.0539079699518013),\n",
      " ('Vertical_Distance_To_Hydrology', 0.03757878547476739),\n",
      " ('Hillshade_Noon', 0.0267531803902),\n",
      " ('Aspect', 0.02597171743170898),\n",
      " ('Wilderness_Area_0', 0.025184332508522863),\n",
      " ('Hillshade_9am', 0.022950425272983688),\n",
      " ('Slope', 0.019093146216324422),\n",
      " ('Hillshade_3pm', 0.013008164267475177),\n",
      " ('Soil_Type_3', 0.008735886291470128),\n",
      " ('Wilderness_Area_2', 0.008294107551219232),\n",
      " ('Soil_Type_21', 0.008117574971734605),\n",
      " ('Soil_Type_22', 0.007624249436234323),\n",
      " ('Soil_Type_31', 0.007233492036864359),\n",
      " ('Soil_Type_1', 0.006660088011108301),\n",
      " ('Wilderness_Area_1', 0.006367980167698458),\n",
      " ('Soil_Type_28', 0.00620464903456658),\n",
      " ('Soil_Type_30', 0.006164553726460858),\n",
      " ('Soil_Type_38', 0.00536598920615657),\n",
      " ('Soil_Type_32', 0.005176133107166592),\n",
      " ('Soil_Type_9', 0.004850333123889768),\n",
      " ('Soil_Type_23', 0.004607705887231824),\n",
      " ('Soil_Type_37', 0.003720052941849092),\n",
      " ('Soil_Type_2', 0.003323401842747866),\n",
      " ('Soil_Type_29', 0.0031531655429279026),\n",
      " ('Soil_Type_12', 0.002959045651564347),\n",
      " ('Soil_Type_11', 0.002044629195376989),\n",
      " ('Soil_Type_16', 0.0020328155201991354),\n",
      " ('Soil_Type_10', 0.001964298742174543),\n",
      " ('Soil_Type_19', 0.0016823161166203938),\n",
      " ('Wilderness_Area_3', 0.0011897928651961804),\n",
      " ('Soil_Type_34', 0.0011197681964334994),\n",
      " ('Soil_Type_15', 0.0009229199779657508),\n",
      " ('Soil_Type_0', 0.0008012937774930774),\n",
      " ('Soil_Type_39', 0.0007470761284816525),\n",
      " ('Soil_Type_4', 0.0005793663882948906),\n",
      " ('Soil_Type_5', 0.0005693901009046176),\n",
      " ('Soil_Type_26', 0.0004811767368803343),\n",
      " ('Soil_Type_8', 0.00038737167143250797),\n",
      " ('Soil_Type_20', 0.0003644008794540685),\n",
      " ('Soil_Type_33', 0.0003310444136375619),\n",
      " ('Soil_Type_18', 0.00030476199137068234),\n",
      " ('Soil_Type_13', 0.0002296641786133689),\n",
      " ('Soil_Type_27', 7.229919282114018e-05),\n",
      " ('Soil_Type_25', 6.990653225303312e-05),\n",
      " ('Soil_Type_24', 6.881985862988237e-05),\n",
      " ('Soil_Type_35', 3.1894928303759197e-05),\n",
      " ('Soil_Type_17', 2.640569184149545e-05),\n",
      " ('Soil_Type_7', 2.0262163213436127e-05),\n",
      " ('Soil_Type_36', 1.388561129515786e-05),\n",
      " ('Soil_Type_6', 0.0),\n",
      " ('Soil_Type_14', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "forest_model = best_model.stages[1]  # e non [2] (nota mia)\n",
    "\n",
    "feature_importance_list = list(zip(input_cols,\n",
    "                                  forest_model.featureImportances.toArray()))\n",
    "feature_importance_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "pprint(feature_importance_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ae519",
   "metadata": {},
   "source": [
    "# Le previsioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f4691bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T15:30:05.898777Z",
     "start_time": "2023-06-28T15:30:05.890799Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'unencode_one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2204/3571183008.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0munenc_test_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munencode_one_hot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munenc_test_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cover_Type\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mselect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"prediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'unencode_one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "unenc_test_data = unencode_one_hot(test_data)\n",
    "\n",
    "best_model.transform(unenc_test_data.drop(\"Cover_Type\")).\\\n",
    "                    select(\"prediction\").show(1)   # --> l'accuratezza del random forest (rispetto all'albero singolo)\n",
    "                                                   #     aumenta leggermente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17348429",
   "metadata": {},
   "source": [
    "# Chiusura della sessione Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4623cc",
   "metadata": {},
   "source": [
    "E' sempre bene chiudere la sessione Spark, come anche suggerito [qui](https://stackoverflow.com/questions/44058122/what-happens-if-sparksession-is-not-closed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74787f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba11dfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "253.729px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
